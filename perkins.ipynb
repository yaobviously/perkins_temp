{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perkins.ipynb",
      "provenance": [],
      "mount_file_id": "1_QJ13QQxNaNbQQvIaFWLy20jvrs4MgWM",
      "authorship_tag": "ABX9TyP8B4/AWrUVIU0Mfg5wN7jM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaobviously/perkins_temp/blob/main/perkins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXsjTbsgPwta"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dll-fa2CP0cO"
      },
      "source": [
        "pop_csv = '/content/drive/MyDrive/Temperature_Perkins/Population Data.csv'\n",
        "temp_csv = '/content/drive/MyDrive/Temperature_Perkins/Temperature Data.csv'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMwBV_2BP2uy"
      },
      "source": [
        "def load_transform_data():\n",
        "  \"\"\"\n",
        "  Preparing the temperature and population datasets for visualization and \n",
        "  analysis\n",
        "  \"\"\"\n",
        "\n",
        "  temp_df = pd.read_csv(temp_csv, parse_dates=['location_date'])\n",
        "\n",
        "  pop_df = pd.read_csv(pop_csv)\n",
        "\n",
        "  # case normalizing pop columns\n",
        "  pop_df.columns = pop_df.columns.str.lower()\n",
        "\n",
        "  # dropping redundant columns\n",
        "  col_drop = ['country_name', 'country_code', 'continent']\n",
        "  temp_df = temp_df.drop(col_drop, axis=1)\n",
        "\n",
        "  # renaming columns\n",
        "  temp_df = temp_df.rename(columns={'temp_mean_c': 'mean_temp',\n",
        "                                    'temp_min_c' : 'min_temp',\n",
        "                                    'temp_max_c' : 'max_temp'})\n",
        "\n",
        "  # making it easier to merge later\n",
        "  temp_df['name'] = [x.split('/')[0] for x in temp_df['name']]\n",
        "  temp_df = temp_df.rename(columns={'name':'city'})\n",
        "\n",
        "  # creating a city dictionary to find matching city pops\n",
        "  city_dict = {'St Louis' : 'St. Louis', 'NYC' : 'New York', \"Chicago O'Hare\" : 'Chicago',\n",
        "               'Covington': 'Cincinnati', 'Wash DC' : 'Washington', 'Windsor Locks' : 'Hartford'\n",
        "               }\n",
        "  temp_df['city'] = temp_df['city'].map(city_dict).fillna(temp_df['city'])\n",
        "\n",
        "  # merging the dataframes\n",
        "  merged_df = pd.merge(temp_df, pop_df, how='left', on='city')\n",
        "  merged_df = merged_df.set_index('location_date').sort_index()\n",
        "  \n",
        "  # creating a function to find the dates with missing values for each\n",
        "  # station and then appending all of those dates to the main dataframe\n",
        "\n",
        "  days = merged_df.index.unique()\n",
        "\n",
        "  def find_miss_days(station_code = 'KLIT'):\n",
        "\n",
        "    df_ = merged_df[merged_df['station_code'] == station_code]\n",
        "\n",
        "    indexes = set(df_.index)\n",
        "    dates_missing = set(days).difference(indexes)\n",
        "\n",
        "    val_dict = {'city' : df_['city'][0],\n",
        "                'station_code' : station_code,\n",
        "                'state' : df_['state'][0]\n",
        "                }\n",
        "\n",
        "    new_df = pd.DataFrame(val_dict, index=tuple(dates_missing))\n",
        "\n",
        "    return new_df\n",
        "\n",
        "  df_append = [find_miss_days(code) for code in trial.station_code.unique()]\n",
        "  df_concat = pd.concat(new_list)\n",
        "\n",
        "  df = merged_df.append(df_concat)\n",
        "\n",
        "  # extracting month from index to compute monthly expanding averages for each \n",
        "  # location\n",
        "  df['month'] = pd.DatetimeIndex(df.index).month\n",
        "  df['avg_daily_for_month'] = (df\n",
        "                               .groupby(['city', 'month'])['mean_temp']\n",
        "                               .transform(lambda x: x.expanding().mean()\n",
        "                                ))\n",
        "  \n",
        "  df['avg_daily_max_month'] = (df\n",
        "                              .groupby(['city', 'month'])['max_temp']\n",
        "                              .transform(lambda x: x.expanding().mean()\n",
        "                              ))\n",
        "  \n",
        "  df['avg_daily_min_month'] = (df\n",
        "                              .groupby(['city', 'month'])['min_temp']\n",
        "                              .transform(lambda x: x.expanding().mean()\n",
        "                                 ))\n",
        "  df = df.sort_index()\n",
        "  df = df.round(2)\n",
        "  \n",
        "  return df\n"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yUvEfmBdjWG"
      },
      "source": [
        "df = load_transform_data()"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKUlhtSoWfW4"
      },
      "source": [
        "def plot_city(city = 'Sacramento', duration='W'):\n",
        "\n",
        "  cols = ['mean_temp', 'max_temp', 'min_temp']\n",
        "\n",
        "  df_ = df[df['city'] == city]\n",
        "\n",
        "  return df_[cols].resample(duration).mean().plot(figsize=(24,5), grid=True, legend=True)"
      ],
      "execution_count": 95,
      "outputs": []
    }
  ]
}